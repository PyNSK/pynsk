<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>PyNSK - Новосибирское Python сообщество</title><link>http://pynsk.ru/</link><description></description><atom:link href="http://pynsk.ru/feeds/izvlechenie-informatsii.rss.xml" rel="self"></atom:link><lastBuildDate>Wed, 23 Sep 2015 10:00:00 +0600</lastBuildDate><item><title>Извлечение информации: grab - фреймворк для веб-парсинга</title><link>http://pynsk.ru/posts/2015/%D1%81%D0%B5%D0%BD%D1%82./23/izvlechenie-informatsii-grab-freimvork-dlia-veb-parsinga/</link><description>&lt;p&gt;Grab — python библиотека для парсинга сайтов&lt;/p&gt;
&lt;p&gt;Её основные функции:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Подготовка сетевого запроса (cookies, http-заголовки, POST/GET данные)&lt;/li&gt;
&lt;li&gt;Запрос на сервер (возможно через HTTP/SOCKS прокси)&lt;/li&gt;
&lt;li&gt;Получение ответа сервера и его первоначальная обработка (парсинг заголовков, парсинг cookies, определение кодировки документа, обработка редиректа (поддерживаются даже редирект в meta refresh тэге))&lt;/li&gt;
&lt;li&gt;Работа с DOM-деревом ответа (если это HTML-документ)&lt;/li&gt;
&lt;li&gt;Работа с формами (заполнение, автозаполнение)&lt;/li&gt;
&lt;li&gt;Отладка: логирование процесса в консоль, сетевых запросов и ответов в файлы&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;В чем же особенность?&lt;/p&gt;
&lt;p&gt;Если scrapy — это реально паук, бегает по сети, тянет в тыщу потоков информацию, то grab — это скорее швейцарский нож, вы его берёте и начинает вдумчиво колупать сайт.&lt;/p&gt;
&lt;p&gt;Пощупать модуль:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://grablib.org/ru/"&gt;http://grablib.org/ru/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Image" src="https://s-media-cache-ak0.pinimg.com/736x/0e/ef/7e/0eef7e463459b10b3ea1f3f21b03d653.jpg" /&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexander Sapronov</dc:creator><pubDate>Wed, 23 Sep 2015 10:00:00 +0600</pubDate><guid>tag:pynsk.ru,2015-09-23:posts/2015/сент./23/izvlechenie-informatsii-grab-freimvork-dlia-veb-parsinga/</guid><category>grab</category><category>parsing</category><category>web parsing</category><category>crawler</category><category>парсинг</category></item><item><title>Извлечение информации: скачиваем список ссылок с помощью asyncio</title><link>http://pynsk.ru/posts/2015/%D1%81%D0%B5%D0%BD%D1%82./09/izvlechenie-informatsii-skachivaem-spisok-ssylok-s-pomoshchiu-asyncio/</link><description>&lt;p&gt;Порой возникают рутинные задачи, которые не хочется делать руками. Примером такой задачи может являться - скачать множество страниц по ссылкам. Если 5 ссылок еще вручную сохранить можно, а если их 1000? или 6250, как было в моем случае. &lt;/p&gt;
&lt;p&gt;На Python эту задачу можно с помощью модуля asyncio и aiohttp. &lt;/p&gt;
&lt;p&gt;Вот такой код можно написать за пару минут:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;asyncio&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;aiohttp&lt;/span&gt;

&lt;span class="nd"&gt;@asyncio.coroutine&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;yield from&lt;/span&gt; &lt;span class="n"&gt;aiohttp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;GET&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;yield from&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;yield from&lt;/span&gt; &lt;span class="n"&gt;save_page&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c"&gt;# сохраняем страницу в файл, или еще куда&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;

&lt;span class="nd"&gt;@asyncio.coroutine&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;download_parallel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;tasks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Task&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;yield from&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gather&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;tasks&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;urls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="err"&gt;список&lt;/span&gt; &lt;span class="err"&gt;ссылок&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c"&gt;# список ссылок&lt;/span&gt;

&lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_event_loop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;loop&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run_until_complete&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;download_parallel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urls&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexander Sapronov</dc:creator><pubDate>Wed, 09 Sep 2015 10:00:00 +0600</pubDate><guid>tag:pynsk.ru,2015-09-09:posts/2015/сент./09/izvlechenie-informatsii-skachivaem-spisok-ssylok-s-pomoshchiu-asyncio/</guid><category>asyncio</category><category>aiohttp</category></item><item><title>Извлечение информации: парсинг дат/времени</title><link>http://pynsk.ru/posts/2015/%D0%B0%D0%B2%D0%B3./19/izvlechenie-informatsii-parsing-datvremeni/</link><description>&lt;p&gt;Извлечение информации из текста/web-страниц сопряжено с эвристиками. 
Одна из проблем, с которой сталкиваются разработчики - как парсить даты. Даты можно написать 100 и одним способом:
tomorrow, а еще 4/4/80 или March 5th, 1980. И какой код писать, чтобы понять эти даты?&lt;/p&gt;
&lt;p&gt;К счастью, код уже написан - &lt;a href="https://github.com/bear/parsedatetime"&gt;https://github.com/bear/parsedatetime&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Данная библиотека позволяет спарсить время в самых различных форматах.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexander Sapronov</dc:creator><pubDate>Wed, 19 Aug 2015 08:00:00 +0600</pubDate><guid>tag:pynsk.ru,2015-08-19:posts/2015/авг./19/izvlechenie-informatsii-parsing-datvremeni/</guid><category>парсинг</category></item><item><title>Парсинг и Python: mechanize</title><link>http://pynsk.ru/posts/2015/%D0%B0%D0%B2%D0%B3./12/parsing-i-python-mechanize/</link><description>&lt;p&gt;Для сбора данных с Web-страниц в Python существует библиотека mechanize, автоматизирующая взаимодействие с Web-сайтами. Часто используемая совместно с ней библиотека Beautiful Soup помогает понять тот «почти-HTML» код, который обычно находится на Web-сайтах.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.ibm.com/developerworks/ru/library/l-python-mechanize-beautiful-soup/"&gt;http://www.ibm.com/developerworks/ru/library/l-python-mechanize-beautiful-soup/&lt;/a&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexander Sapronov</dc:creator><pubDate>Wed, 12 Aug 2015 17:00:00 +0600</pubDate><guid>tag:pynsk.ru,2015-08-12:posts/2015/авг./12/parsing-i-python-mechanize/</guid><category>парсинг</category><category>mechanize</category></item><item><title>Python и интересный парсинг сайтов</title><link>http://pynsk.ru/posts/2015/%D0%B0%D0%B2%D0%B3./05/python-i-interesnyi-parsing-saitov/</link><description>&lt;p&gt;Излечение информации со страниц может быть интересным. Рекомендуем к просмотру видео
&lt;a class='embedly-card' data-card-chrome='0' href='http://www.youtube.com/watch?v=hj-8l3AejNc'&gt;&lt;/a&gt;
            &lt;script&gt;
            !function(a){
                var b="embedly-platform",c="script";
                if(!a.getElementById(b)){
                    var d=a.createElement(c);
                    d.id=b;
                    d.src=("https:"===document.location.protocol?"https":"http")+"://cdn.embedly.com/widgets/platform.js";
                    var e=document.getElementsByTagName(c)[0];e.parentNode.insertBefore(d,e)}
                }(document);
            &lt;/script&gt;
            &lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexander Sapronov</dc:creator><pubDate>Wed, 05 Aug 2015 17:00:00 +0600</pubDate><guid>tag:pynsk.ru,2015-08-05:posts/2015/авг./05/python-i-interesnyi-parsing-saitov/</guid></item><item><title>Парсинг с помощью asyncio</title><link>http://pynsk.ru/posts/2015/%D0%B8%D1%8E%D0%BB%D1%8F/29/parsing-s-pomoshchiu-asyncio/</link><description>&lt;p&gt;Парсинг сайтов это вечная задача. Сайтов много, данных много и все они разные.
Для задач парсинга существует великое разнообразие инструментов.&lt;/p&gt;
&lt;p&gt;В Python 3-ей версии появился стандартный модуль для создания асинхронных программ. И грех не воспользоваться данной возможностью.&lt;/p&gt;
&lt;p&gt;Примером парсинга на asyncio может послужить эта статья 
&lt;a href="http://olegwock.net/blog/python/byistryiy-parsing-na-python-s-pomoshhyu-asyncio/"&gt;http://olegwock.net/blog/python/byistryiy-parsing-na-python-s-pomoshhyu-asyncio/&lt;/a&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Alexander Sapronov</dc:creator><pubDate>Wed, 29 Jul 2015 17:00:00 +0600</pubDate><guid>tag:pynsk.ru,2015-07-29:posts/2015/июля/29/parsing-s-pomoshchiu-asyncio/</guid><category>asyncio</category><category>парсинг</category></item></channel></rss>